from google.colab import drive
drive.mount('/content/drive')

!ls "/content/drive/MyDrive/Gaze detection/"

import os

print(os.path.exists("/content/drive/MyDrive/Gaze detection/X_mpiigaze_normalized.mat"))
print(os.path.exists("/content/drive/MyDrive/Gaze detection/Y_mpiigaze_gaze.mat"))

print(os.path.getsize("/content/drive/MyDrive/Gaze detection/Y_mpiigaze_gaze.mat"))

import h5py
import numpy as np

X_path = "/content/drive/MyDrive/Gaze detection/X_mpiigaze_normalized.mat"
X_file = h5py.File(X_path, 'r')

print(list(X_file.keys()))

print(X_file['X'].shape)

import scipy.io

Y_path = "/content/drive/MyDrive/Gaze detection/Y_mpiigaze_gaze.mat"
Y_data = scipy.io.loadmat(Y_path)

print(Y_data.keys())  # just to confirm

Y = Y_data['Y']       # make sure the key is correct
print(Y.shape)

X_dataset = X_file['X']

import numpy as np

indices = np.random.choice(len(X_dataset), 20000, replace=False)
indices = np.sort(indices)

X_sample = X_dataset[indices].astype("float32") / 255.0
Y_sample = Y[indices]

print(X_sample.shape)
print(Y_sample.shape)

X_sample = X_sample.reshape(-1, 64, 64, 1)
print(X_sample.shape)
Y_sample = Y[indices]
print(Y_sample.shape)

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(
    X_sample, Y_sample,
    test_size=0.2,
    random_state=42
)

print(X_train.shape)
print(Y_train.shape)

import numpy as np
print(np.mean(np.linalg.norm(Y_sample, axis=1)))

import sys
print(sys.executable)
!{sys.executable} -m pip install tensorflow-cpu

import tensorflow as tf
from tensorflow.keras import layers

def cosine_loss(y_true, y_pred):
    dot = tf.reduce_sum(y_true * y_pred, axis=1)
    return 1 - tf.reduce_mean(dot)

model = tf.keras.Sequential([

    layers.Conv2D(32, (3,3), padding='same', input_shape=(64,64,1)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), padding='same'),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(128, (3,3), padding='same'),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(256, (3,3), padding='same'),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPooling2D(2,2),

    layers.GlobalAveragePooling2D(),

    layers.Dense(256),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.Dropout(0.4),

    layers.Dense(3),
    layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss=cosine_loss
)

model.summary()

model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.3))
model.add(layers.Dense(3))
model.add(layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))

def cosine_loss(y_true, y_pred):
    dot = tf.reduce_sum(y_true * y_pred, axis=1)
    return 1 - tf.reduce_mean(dot)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),
    loss=cosine_loss
)

history = model.fit(
    X_train, Y_train,
    epochs=10,
    batch_size=32,
    validation_data=(X_test, Y_test),
    verbose=1
)

import numpy as np

pred = model.predict(X_test)

dot = np.sum(pred * Y_test, axis=1)
dot = np.clip(dot, -1.0, 1.0)
angles = np.arccos(dot)

mean_error_deg = np.mean(angles) * 180 / np.pi
print("Mean Angular Error (degrees):", mean_error_deg)



